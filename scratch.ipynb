{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4becc1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5971b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads the updated csv for the 2023 season\n",
    "import gdown\n",
    "\n",
    "def update_df():\n",
    "    '''\n",
    "    Download most recent csv file, concat with rest of data, return the full df\n",
    "    '''\n",
    "    output = \"lol_2023.csv\" #What to save the downloaded file as\n",
    "    id = \"1XXk2LO0CsNADBB1LRGOV5rUpyZdEZ8s2\" #The id from the google drive file\n",
    "    gdown.download(id=id, output=output, quiet=False)\n",
    "    \n",
    "    df_2021 = pd.read_csv('lol_2021.csv')\n",
    "    df_2022 = pd.read_csv('lol_2022.csv')\n",
    "    df_2023 = pd.read_csv('lol_2023.csv')\n",
    "    df = pd.concat([df_2021,df_2022,df_2023])\n",
    "    return df\n",
    "\n",
    "def get_wiki():\n",
    "    '''\n",
    "    Returns chart from wikipedia containing info for Tier 1 and Tier 2 leagues\n",
    "    Returns tier1, tier2\n",
    "    '''\n",
    "    wiki = pd.read_html('https://en.wikipedia.org/wiki/List_of_League_of_Legends_leagues_and_tournaments')\n",
    "    return wiki[1], wiki[3]\n",
    "\n",
    "def add_opp_name(df): #tup = list of tuples\n",
    "    # Create an 'opp_name' column for each row\n",
    "    evens = range(0,df.shape[0],2)\n",
    "    odds = range(1,df.shape[0],2)\n",
    "    tup = [(a,b) for a,b in zip(evens,odds)] # list of tuples\n",
    "    \n",
    "    for t in tup: #iterate through list of tuples\n",
    "        a,b= t #unpack each tuple into two values\n",
    "        df.loc[a,'opp_name']=df.teamname.loc[b] #create new column w/opp_name\n",
    "        df.loc[b,'opp_name']=df.teamname.loc[a]\n",
    "    return df\n",
    "\n",
    "def win_percent(elo_a,elo_b): #Calculate odds to win based off of elo rankings\n",
    "    return 1/(1+10**((elo_b-elo_a)/400)) #elo_a is who you're calculating for, elo_b is opponent\n",
    "\n",
    "def win_prob(x): # x is the American odds (-110,110,etc.) Calculates probably of winning\n",
    "    if x < 0 :\n",
    "        x = x*-1\n",
    "        return x / (x + 100)\n",
    "    else: \n",
    "        return 100 / (x + 100)\n",
    "\n",
    "def gain_elo(elo,opp_elo,k=32): #Gain elo after a win, k=24, expected = 1\n",
    "    return int(elo+k*(1-win_percent(elo,opp_elo)))\n",
    "\n",
    "def lose_elo(elo,opp_elo,k=32): #Lose elo after a loss, k=24, expected = 0\n",
    "    return int(elo+k*(0-win_percent(elo,opp_elo)))\n",
    "\n",
    "def tie_elo(elo,opp_elo,k=32): #Lose elo after a loss, k=24, expected = .5\n",
    "    return int(elo+k*(.5-win_percent(elo,opp_elo)))\n",
    "\n",
    "\n",
    "def wrangle_df(df):\n",
    "    leagues = ['LCK','LPL','LEC','LCS','PCS','VCS','CBLOL','LJL','LLA'] # These are my 9 tier 1 leagues that I'll keep\n",
    "    \n",
    "    df = df[df.league.isin(leagues)] #Filter out non Tier-1 leagues\n",
    "    df = df[df.position=='team'] #Remove individual player stats\n",
    "    \n",
    "    df.split = df.split.str.replace('Split 1','Spring').str.replace('Split 2','Summer') #Rename 'split' names\n",
    "    df.split = df.split.str.replace('Opening','Spring').str.replace('Closing','Summer')\n",
    "\n",
    "    cols = ['teamname','league','split','date', 'side', 'gamelength','game', 'result', 'teamkills', \n",
    "            'teamdeaths', 'firstblood', 'position', 'dragons', 'barons', 'opp_barons','towers', 'opp_towers', \n",
    "            'inhibitors', 'opp_inhibitors', 'damagetochampions', 'damagetakenperminute', 'wardsplaced', 'wardskilled', \n",
    "            'controlwardsbought', 'totalgold', 'gspd'] #Columns to keep\n",
    "\n",
    "    df = df[cols] #Remove unwanted columns\n",
    "    df = df.dropna() #Drop nan values\n",
    "    \n",
    "    df.date = pd.to_datetime(df.date,infer_datetime_format=True) #Change to datetime object\n",
    "    del df['position'] # Delete 'position' column\n",
    "    df = df.sort_values('date') #Sort by date\n",
    "    df = df.reset_index(drop=True) #Reset index\n",
    "    df.side = np.where(df.side=='Blue',1,0) #Add 'side' column for 'blue' or 'red'\n",
    "    df.rename(columns={'side':'blue_side'},inplace = True) #Change 'side' to 'blue_side'\n",
    "    \n",
    "    df['old_elo']=np.NaN #create new elo column\n",
    "    df['new_elo']=np.NaN\n",
    "    df['opp_elo']=np.NaN\n",
    "    df.loc[df[~df.teamname.duplicated()].index,'old_elo']=1200 #set elo for first game to 1200 for each team\n",
    "\n",
    "    df = add_opp_name(df) #adds opponents' name\n",
    "    \n",
    "    for i in range(0,df.shape[0]):\n",
    "        opp_name = df.loc[i,'opp_name']\n",
    "        df.loc[i,'opp_elo'] = df[(df.teamname==opp_name)&(~df.old_elo.isna())]['old_elo'].iloc[-1]\n",
    "        if df.loc[i,'result'] == 1:\n",
    "            df.loc[i,'new_elo'] = gain_elo(df.loc[i,'old_elo'],df.loc[i,'opp_elo'])\n",
    "        else:\n",
    "            df.loc[i,'new_elo'] = lose_elo(df.loc[i,'old_elo'],df.loc[i,'opp_elo'])\n",
    "\n",
    "        team_name = df.loc[i,'teamname']\n",
    "        try:\n",
    "            next_game_index = df[(df.teamname==team_name)&df.old_elo.isna()]['old_elo'].index[0]\n",
    "            df.loc[next_game_index,'old_elo'] = df[(df.teamname==team_name)&(~df.new_elo.isna())]['new_elo'].iloc[-1]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    df.to_csv('final.csv') #Save to csv file\n",
    "    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a604fcd",
   "metadata": {},
   "source": [
    "# Update and wrangle professional games for Spring and Summer splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb9081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1XXk2LO0CsNADBB1LRGOV5rUpyZdEZ8s2\n",
      "To: /Users/thegootch/codeup-data-science/league/lol_2023.csv\n",
      "100%|██████████████████████████████████████| 32.6M/32.6M [00:03<00:00, 9.95MB/s]\n",
      "/var/folders/fz/0282wvb93rn0lm_p0nscw1sm0000gn/T/ipykernel_7318/3407151170.py:1: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  df = update_df()\n"
     ]
    }
   ],
   "source": [
    "df = update_df()\n",
    "df.to_csv('raw.csv')\n",
    "df = wrangle_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf72620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3462fc11",
   "metadata": {},
   "source": [
    "# Sports Betting Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09f01f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_league(team): #Returns a league (\"LCS,LPL,etc.\") sorted by latest elo\n",
    "    return current_elo[current_elo.league==team].sort_values('new_elo',ascending=False)\n",
    "\n",
    "def get_teams(df, teams, opponents, bet_odds):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with 'home' and 'away' teams with elos and implied odds.\n",
    "    \"\"\"\n",
    "    team_list = []\n",
    "    for team, opponent, odds in zip(teams, opponents, bet_odds):\n",
    "        row1 = df[df.teamname==team][['teamname', 'new_elo']]\n",
    "        row1['odds'] = odds[0]\n",
    "        row2 = df[df.teamname==opponent][['teamname', 'new_elo']]\n",
    "        row2['odds'] = odds[1]\n",
    "        row3 = pd.concat([row1, row2])\n",
    "        row3.columns = ['teamname', 'elo', 'odds']\n",
    "        row3['opponent'] = [row2.teamname.iloc[0], row1.teamname.iloc[0]]\n",
    "        row3['next_opp_elo'] = [row2.new_elo.iloc[0], row1.new_elo.iloc[0]]\n",
    "        team_list.append(row3)\n",
    "    temp = pd.concat(team_list)\n",
    "    temp = temp[['teamname', 'elo', 'opponent', 'next_opp_elo', 'odds']]\n",
    "    temp['implied_odds'] = temp.odds.apply(win_prob)\n",
    "    temp['elo_odds'] = temp.apply(lambda row: win_percent(row['elo'], row['next_opp_elo']), axis=1)\n",
    "    temp['odds_diff'] = temp.elo_odds - temp.implied_odds\n",
    "    temp.sort_values('odds_diff', ascending=False, inplace=True)\n",
    "    return temp.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "081c8f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3442: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#Read in df and create 'current_elo' df\n",
    "df = pd.read_csv('final.csv',index_col=0) \n",
    "raw = pd.read_csv('raw.csv',index_col=0)\n",
    "\n",
    "#'current_elo' contains every team and their latest elo\n",
    "current_elo = df[~df.teamname.duplicated(keep='last')]\\\n",
    "[['teamname','league','opp_name','old_elo','opp_elo','new_elo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d99bb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_league' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_league\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLCS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_league' is not defined"
     ]
    }
   ],
   "source": [
    "get_league(\"LCS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8588fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input home and away teams with their odds and get back a df with the difference between betting odds and elo odds\n",
    "home = ['Cloud9','eStar']\n",
    "away = ['Bilibili Gaming','Rogue Warriors']\n",
    "odds = [(-230,280),(160,-110)]\n",
    "monies = get_teams(current_elo,home,away,odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02c0a9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamname</th>\n",
       "      <th>elo</th>\n",
       "      <th>opponent</th>\n",
       "      <th>next_opp_elo</th>\n",
       "      <th>odds</th>\n",
       "      <th>implied_odds</th>\n",
       "      <th>elo_odds</th>\n",
       "      <th>odds_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rogue Warriors</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>eStar</td>\n",
       "      <td>980.0</td>\n",
       "      <td>-110</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.630730</td>\n",
       "      <td>0.106921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bilibili Gaming</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>Cloud9</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>280</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.328759</td>\n",
       "      <td>0.065602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eStar</td>\n",
       "      <td>980.0</td>\n",
       "      <td>Rogue Warriors</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>160</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.369270</td>\n",
       "      <td>-0.015346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cloud9</td>\n",
       "      <td>1373.0</td>\n",
       "      <td>Bilibili Gaming</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>-230</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.671241</td>\n",
       "      <td>-0.025729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          teamname     elo         opponent  next_opp_elo  odds  implied_odds  \\\n",
       "0   Rogue Warriors  1073.0            eStar         980.0  -110      0.523810   \n",
       "1  Bilibili Gaming  1249.0           Cloud9        1373.0   280      0.263158   \n",
       "2            eStar   980.0   Rogue Warriors        1073.0   160      0.384615   \n",
       "3           Cloud9  1373.0  Bilibili Gaming        1249.0  -230      0.696970   \n",
       "\n",
       "   elo_odds  odds_diff  \n",
       "0  0.630730   0.106921  \n",
       "1  0.328759   0.065602  \n",
       "2  0.369270  -0.015346  \n",
       "3  0.671241  -0.025729  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88a385f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports_book:  0.52\n",
      "elo_odds:  0.63\n"
     ]
    }
   ],
   "source": [
    "print('sports_book: ', round(win_prob(-110), 2)) #based on betting odds\n",
    "print('elo_odds: ', round(win_percent(1073, 980), 2)) #based on elo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aac6cb",
   "metadata": {},
   "source": [
    "# Don't go past here yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78849392",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = train.select_dtypes(['int','float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(groupby):\n",
    "    groupby['target']=groupby['result'].shift(-1)\n",
    "    return groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(df):\n",
    "    df = df.groupby('teamname').apply(create_target)\n",
    "    df.loc[pd.isnull(df.target),'target'] =2\n",
    "    df.target = df.target.astype(int,errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b88c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_target(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #scale all numerical columns\n",
    "\n",
    "removed_columns = ['teamname','league','date','target','opp_name']\n",
    "selected_columns = df.columns[~df.columns.isin(removed_columns)]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[selected_columns] = scaler.fit_transform(df[selected_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling averages for columns, concat as new columns to df\n",
    "\n",
    "\n",
    "def rolling(team):\n",
    "    rolling = team.rolling(10).mean()\n",
    "    return rolling\n",
    "\n",
    "def add_rolling(df):\n",
    "    cols = ['gamelength','teamkills','teamdeaths','firstblood','dragons','barons','opp_barons','towers','opp_towers',\\\n",
    "       'inhibitors','opp_inhibitors','damagetochampions','damagetakenperminute','wardsplaced','wardskilled',\\\n",
    "       'controlwardsbought','totalgold','gspd']\n",
    "\n",
    "    df_rolling=df[list(cols)+['teamname']]\n",
    "    \n",
    "    \n",
    "    df_rolling = df_rolling.groupby('teamname',group_keys=False)[cols].apply(rolling)\n",
    "\n",
    "    rolling_cols = [f'{col}_rolling' for col in df_rolling.columns]\n",
    "    df_rolling.columns = rolling_cols\n",
    "    df = pd.concat([df,df_rolling],axis=1)\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_opp(team):\n",
    "    team['next_opp'] = team['opp_name'].shift(-1)\n",
    "    return team\n",
    "def add_opp(df):\n",
    "    df = df.groupby('teamname').apply(next_opp)\n",
    "    df.loc[df.next_opp.isnull(),'next_opp'] = 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_opp(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_side(team):\n",
    "    team['next_blue'] = team['blue_side'].shift(-1)\n",
    "    return team\n",
    "\n",
    "def add_next_side(df):\n",
    "    df = df.groupby('teamname').apply(next_side)\n",
    "    df.loc[df.next_blue.isnull(),'next_blue']=2\n",
    "    df.next_blue = df.next_blue.astype(int,errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_date(team):\n",
    "    team['next_date'] = team['date'].shift(-1)\n",
    "    return team\n",
    "\n",
    "def add_next_date(df):\n",
    "    df = df.groupby('teamname').apply(next_date)\n",
    "    df.loc[df.next_date.isnull(),'next_date']=2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee28602",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = df.merge(df[rolling_cols + [\"next_opp\", \"next_date\", \"teamname\"]], left_on=[\"teamname\", \"next_date\"], \\\n",
    "                right_on=[\"next_opp\", \"next_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3849bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "def create_objects():\n",
    "    rr = RidgeClassifier(solver ='sag',normalize=False,)\n",
    "    split = TimeSeriesSplit(n_splits=3)\n",
    "    sfs = SequentialFeatureSelector(rr, n_features_to_select=14,direction='backward',cv=split,n_jobs=-1)\n",
    "\n",
    "create_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = list(full.columns[full.dtypes=='object']) + removed_columns\n",
    "selected_columns = full.columns[~full.columns.isin(removed_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98214a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.fit(full[selected_columns],full['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5df7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = selected_columns[sfs.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628bef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = backtest(full,rr,selectors,'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf2301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictions.actual,predictions.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f054f6a",
   "metadata": {},
   "source": [
    ".5665 'forward', rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c0ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_split(x, num_bins): #Split my df into equal splits to perform backtesting\n",
    "    quotient, remainder = divmod(x, num_bins)\n",
    "    bins = [quotient + 1] * remainder + [quotient] * (num_bins - remainder)\n",
    "    count = 0\n",
    "    new_list = []\n",
    "    for b in bins:\n",
    "        count += b\n",
    "        new_list.append(count)\n",
    "    return new_list\n",
    "\n",
    "splits = near_split(df.shape[0],5)\n",
    "last_split = splits[4]-splits[3] #Difference between last two values for final 'test' set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data,model,predictors,target):\n",
    "    all_predictions= []\n",
    "    \n",
    "    for i in range(0,len(splits)-1):\n",
    "        train = data.loc[:splits[i]]\n",
    "        test = data.loc[splits[i]:splits[i]+last_split]\n",
    "        \n",
    "        model.fit(train[predictors],train[target])\n",
    "        preds = model.predict(test[predictors])\n",
    "        preds = pd.Series(preds,index=test.index)\n",
    "        combined = pd.concat([test[target],preds],axis=1)\n",
    "        combined.columns = ['actual','prediction']\n",
    "        \n",
    "        all_predictions.append(combined)\n",
    "        \n",
    "    return pd.concat(all_predictions)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = backtest(full,rr,selectors,'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9140cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictions.actual,predictions.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d52e2b",
   "metadata": {},
   "source": [
    "### optimize ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full[selectors]\n",
    "y = full['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "ridge = linear_model.Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02daa069",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(\"pca\", pca),\n",
    "                        (\"ridge\", ridge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "normalize = [True, False]\n",
    "solver = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                      ridge__normalize=normalize,\n",
    "                      ridge__solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88430bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS = GridSearchCV(pipe, parameters)\n",
    "clf_GS.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Number Of Components:\", clf_GS.best_estimator_.get_params()[\"pca__n_components\"])\n",
    "print(); print(clf_GS.best_estimator_.get_params()[\"ridge\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51ff65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
