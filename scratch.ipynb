{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4becc1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5971b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads the updated csv for the 2023 season\n",
    "import gdown\n",
    "\n",
    "def update_df():\n",
    "    '''\n",
    "    Download most recent csv file, concat with rest of data, return the full df\n",
    "    '''\n",
    "    output = \"lol_2023.csv\" #What to save the downloaded file as\n",
    "    id = \"1XXk2LO0CsNADBB1LRGOV5rUpyZdEZ8s2\" #The id from the google drive file\n",
    "    gdown.download(id=id, output=output, quiet=False)\n",
    "    \n",
    "    df_2021 = pd.read_csv('lol_2021.csv')\n",
    "    df_2022 = pd.read_csv('lol_2022.csv')\n",
    "    df_2023 = pd.read_csv('lol_2023.csv')\n",
    "    df = pd.concat([df_2021,df_2022,df_2023])\n",
    "    return df\n",
    "\n",
    "def get_wiki():\n",
    "    '''\n",
    "    Returns chart from wikipedia containing info for Tier 1 and Tier 2 leagues\n",
    "    Returns tier1, tier2\n",
    "    '''\n",
    "    wiki = pd.read_html('https://en.wikipedia.org/wiki/List_of_League_of_Legends_leagues_and_tournaments')\n",
    "    return wiki[1], wiki[3]\n",
    "\n",
    "def add_opp_name(df): #tup = list of tuples\n",
    "    # Create an 'opp_name' column for each row\n",
    "    evens = range(0,df.shape[0],2)\n",
    "    odds = range(1,df.shape[0],2)\n",
    "    tup = [(a,b) for a,b in zip(evens,odds)] # list of tuples\n",
    "    \n",
    "    for t in tup: #iterate through list of tuples\n",
    "        a,b= t #unpack each tuple into two values\n",
    "        df.loc[a,'opp_name']=df.teamname.loc[b] #create new column w/opp_name\n",
    "        df.loc[b,'opp_name']=df.teamname.loc[a]\n",
    "    return df\n",
    "\n",
    "def add_opp_elo(df): #tup = list of tuples\n",
    "    # Create an 'opp_name' column for each row\n",
    "    evens = range(0,df.shape[0],2)\n",
    "    odds = range(1,df.shape[0],2)\n",
    "    tup = [(a,b) for a,b in zip(evens,odds)] # list of tuples\n",
    "    \n",
    "    for t in tup: #iterate through list of tuples\n",
    "        a,b= t #unpack each tuple into two values\n",
    "        df.loc[a,'opp_name']=df.elo.loc[b] #create new column w/opp_name\n",
    "        df.loc[b,'opp_name']=df.elo.loc[a]\n",
    "    return df\n",
    "\n",
    "def win_percent(elo_a,elo_b): #Calculate odds to win based off of elo rankings\n",
    "    return 1/(1+10**((elo_b-elo_a)/400)) #elo_a is who you're calculating for, elo_b is opponent\n",
    "\n",
    "def win_prob(x): # x is the American odds (-110,110,etc.) Calculates probability of winning\n",
    "    if x < 0 :\n",
    "        x = x*-1\n",
    "        return x / (x + 100)\n",
    "    else: \n",
    "        return 100 / (x + 100)\n",
    "\n",
    "def gain_elo(elo,opp_elo,k=32): #Gain elo after a win, k=24, expected = 1\n",
    "    return int(elo+k*(1-win_percent(elo,opp_elo)))\n",
    "\n",
    "def lose_elo(elo,opp_elo,k=32): #Lose elo after a loss, k=24, expected = 0\n",
    "    return int(elo+k*(0-win_percent(elo,opp_elo)))\n",
    "\n",
    "def tie_elo(elo,opp_elo,k=32): #Lose elo after a loss, k=24, expected = .5\n",
    "    return int(elo+k*(.5-win_percent(elo,opp_elo)))\n",
    "\n",
    "\n",
    "def wrangle_df(df):\n",
    "    leagues = ['LCK','LPL','LEC','LCS','PCS','VCS','CBLOL','LJL','LLA','UL','SL','LFL','LCO','CBLOLA'] # These are my 9 tier 1 leagues that I'll keep\n",
    "    df = df[df.league.isin(leagues)] #Grab leagues of interest\n",
    "    df = df[df.position=='team'] #Remove individual player stats\n",
    "    \n",
    "    mapping = {'Excel Esports':'Excel','EDward Gaming':'Edward Gaming','KaBuM! Esports':'KaBuM! e-Sports',\n",
    "     'BISONS ECLUB':'BISONS Eclub','exeed':'Exeed','Grypciocraft Esports':'Grypciocraft',\n",
    "     'Komil&amp;Friends':'Komil&Friends','IZI Dream':'Izi Dream','Team BDS Academy':'Team BDS.A',\n",
    "     'FURIA Academy':'FURIA.A','Fluxo Academy':'Fluxo.A','INTZ Academy':'INTZ.A','KaBuM! Academy':'KaBuM! e-Sports.A',\n",
    "     'LOUD Academy':'LOUD.A','Liberty Academy':'Liberty.A','Los Grandes Academy':'Los Grandes.A',\n",
    "     'RED Academy':'RED Canids.A','Vivo Keyd Stars Academy':'Vivo Keyd Stars.A','paiN Gaming Academy':'paiN Gaming.A',\n",
    "     'MAMMOTH':'Mammoth'}\n",
    "\n",
    "    df.teamname.replace(mapping,inplace=True)\n",
    "    \n",
    "    df.split = df.split.str.replace('Split 1','Spring').str.replace('Split 2','Summer') #Rename 'split' names\n",
    "    df.split = df.split.str.replace('Opening','Spring').str.replace('Closing','Summer')\n",
    "\n",
    "    cols = ['teamname','league','split','date', 'side', 'gamelength','game', 'result', 'teamkills', \n",
    "            'teamdeaths', 'firstblood', 'position', 'dragons', 'barons', 'opp_barons','towers', 'opp_towers', \n",
    "            'inhibitors', 'opp_inhibitors', 'damagetochampions', 'damagetakenperminute', 'wardsplaced', 'wardskilled', \n",
    "            'controlwardsbought', 'totalgold', 'gspd'] #Columns to keep\n",
    "\n",
    "    df = df[cols] #Remove unwanted columns\n",
    "    df = df.dropna() #Drop nan values\n",
    "    \n",
    "    df.date = pd.to_datetime(df.date,infer_datetime_format=True) #Change to datetime object\n",
    "    del df['position'] # Delete 'position' column\n",
    "    df = df.sort_values('date') #Sort by date\n",
    "    df = df.reset_index(drop=True) #Reset index\n",
    "    df.side = np.where(df.side=='Blue',1,0) #Add 'side' column for 'blue' or 'red'\n",
    "    df.rename(columns={'side':'blue_side'},inplace = True) #Change 'side' to 'blue_side'\n",
    "    \n",
    "    df['old_elo']=np.NaN #create new elo column\n",
    "    df['new_elo']=np.NaN\n",
    "    df['opp_elo']=np.NaN\n",
    "    df.loc[df[~df.teamname.duplicated()].index,'old_elo']=1200 #set elo for first game to 1200 for each team\n",
    "\n",
    "    df = add_opp_name(df) #adds opponents' name\n",
    "    \n",
    "    for i in range(0,df.shape[0]):\n",
    "        opp_name = df.loc[i,'opp_name']\n",
    "        df.loc[i,'opp_elo'] = df[(df.teamname==opp_name)&(~df.old_elo.isna())]['old_elo'].iloc[-1]\n",
    "        if df.loc[i,'result'] == 1:\n",
    "            df.loc[i,'new_elo'] = gain_elo(df.loc[i,'old_elo'],df.loc[i,'opp_elo'])\n",
    "        else:\n",
    "            df.loc[i,'new_elo'] = lose_elo(df.loc[i,'old_elo'],df.loc[i,'opp_elo'])\n",
    "\n",
    "        team_name = df.loc[i,'teamname']\n",
    "        try:\n",
    "            next_game_index = df[(df.teamname==team_name)&df.old_elo.isna()]['old_elo'].index[0]\n",
    "            df.loc[next_game_index,'old_elo'] = df[(df.teamname==team_name)&(~df.new_elo.isna())]['new_elo'].iloc[-1]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    df.to_csv('final.csv') #Save to csv file\n",
    "    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a604fcd",
   "metadata": {},
   "source": [
    "# Update and wrangle professional games for Spring and Summer splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4cb9081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1XXk2LO0CsNADBB1LRGOV5rUpyZdEZ8s2\n",
      "To: /Users/thegootch/codeup-data-science/league/lol_2023.csv\n",
      "100%|██████████████████████████████████████| 43.0M/43.0M [00:06<00:00, 6.23MB/s]\n",
      "/var/folders/fz/0282wvb93rn0lm_p0nscw1sm0000gn/T/ipykernel_10482/3407151170.py:1: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  df = update_df()\n"
     ]
    }
   ],
   "source": [
    "df = update_df()\n",
    "df.to_csv('raw.csv')\n",
    "df = wrangle_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf72620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamname</th>\n",
       "      <th>league</th>\n",
       "      <th>date</th>\n",
       "      <th>result</th>\n",
       "      <th>opp_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21009</th>\n",
       "      <td>FunPlus Phoenix</td>\n",
       "      <td>LPL</td>\n",
       "      <td>2023-06-27 09:16:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Weibo Gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21010</th>\n",
       "      <td>Weibo Gaming</td>\n",
       "      <td>LPL</td>\n",
       "      <td>2023-06-27 10:07:33</td>\n",
       "      <td>1</td>\n",
       "      <td>FunPlus Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21011</th>\n",
       "      <td>FunPlus Phoenix</td>\n",
       "      <td>LPL</td>\n",
       "      <td>2023-06-27 10:07:33</td>\n",
       "      <td>0</td>\n",
       "      <td>Weibo Gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21012</th>\n",
       "      <td>Weibo Gaming</td>\n",
       "      <td>LPL</td>\n",
       "      <td>2023-06-27 10:54:57</td>\n",
       "      <td>0</td>\n",
       "      <td>FunPlus Phoenix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21013</th>\n",
       "      <td>FunPlus Phoenix</td>\n",
       "      <td>LPL</td>\n",
       "      <td>2023-06-27 10:54:57</td>\n",
       "      <td>1</td>\n",
       "      <td>Weibo Gaming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              teamname league                date  result         opp_name\n",
       "21009  FunPlus Phoenix    LPL 2023-06-27 09:16:00       1     Weibo Gaming\n",
       "21010     Weibo Gaming    LPL 2023-06-27 10:07:33       1  FunPlus Phoenix\n",
       "21011  FunPlus Phoenix    LPL 2023-06-27 10:07:33       0     Weibo Gaming\n",
       "21012     Weibo Gaming    LPL 2023-06-27 10:54:57       0  FunPlus Phoenix\n",
       "21013  FunPlus Phoenix    LPL 2023-06-27 10:54:57       1     Weibo Gaming"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['teamname','league','date','result','opp_name']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd008f5",
   "metadata": {},
   "source": [
    "# Test Section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fb92dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "def get_unique_values(*lists):\n",
    "    unique_values = set()\n",
    "    for lst in lists:\n",
    "        unique_values.update(lst)\n",
    "    return list(unique_values)\n",
    "\n",
    "def extract_matched_words(text, words_list):\n",
    "    pattern = r\"(?i)(?:{})\".format(\"|\".join(map(re.escape, words_list)))\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n",
    "def list_to_dataframe(lst):\n",
    "    num_columns = 4\n",
    "    num_rows = len(lst) // num_columns\n",
    "    data = [lst[i:i+num_columns] for i in range(0, len(lst), num_columns)]\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def get_historical_odds(league,year):\n",
    "    file_path = f'{league}_{year}.html'\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    right_bold = soup.find_all('div', class_='relative block truncate whitespace-nowrap group-hover:underline font-bold text-gray-dark')\n",
    "    right_bold = [n.text for n in right_bold]\n",
    "\n",
    "    right_grey = soup.find_all('div', class_='relative block truncate whitespace-nowrap group-hover:underline text-gray-dark')\n",
    "    right_grey = [n.text for n in right_grey]\n",
    "\n",
    "    left_grey = soup.find_all('div', class_='relative block truncate whitespace-nowrap group-hover:underline next-m:!ml-auto text-gray-dark')\n",
    "    left_grey = [n.text for n in left_grey]\n",
    "\n",
    "    left_bold = soup.find_all('div', class_='relative block truncate whitespace-nowrap group-hover:underline font-bold next-m:!ml-auto text-gray-dark')\n",
    "    left_bold = [n.text for n in left_bold]\n",
    "\n",
    "    loser_num = soup.find_all('p', class_='height-content !text-black-main min-w-[50px] next-m:min-w-[100%] min-h-full flex-center hover:!bg-gray-medium default-odds-bg-bgcolor border gradient-green-added-border')\n",
    "    loser_num = [n.text for n in loser_num]\n",
    "\n",
    "    winner_num = soup.find_all('p', class_='height-content !text-black-main min-w-[50px] next-m:min-w-[100%] min-h-full flex-center gradient-green hover:!bg-gray-medium default-odds-bg-bgcolor border gradient-green-added-border')\n",
    "    winner_num = [n.text for n in winner_num]\n",
    "\n",
    "    text = soup.text\n",
    "    words_list = get_unique_values(right_bold,right_grey,left_bold,left_grey,winner_num,loser_num)\n",
    "    result = extract_matched_words(text, words_list)\n",
    "\n",
    "    df = list_to_dataframe(result)\n",
    "    df['winner'] = winner_num\n",
    "    df.columns = ['team_a','team_b','a_odds','b_odds','winning_odds']\n",
    "    df.a_odds = pd.to_numeric(df['a_odds'])\n",
    "    df.b_odds = pd.to_numeric(df['b_odds'])\n",
    "    df.winning_odds = pd.to_numeric(df['winning_odds'])\n",
    "    df['year'] = pd.to_numeric(year)\n",
    "    df['league'] = league\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cc0a6172",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2020,2021,2022,2023,2024]\n",
    "leagues = ['lpl','lcs','lec','cblol','ul','sl','lfl','lco','lck']\n",
    "\n",
    "to_combine = []\n",
    "for y in years:\n",
    "    for l in leagues:\n",
    "        try:\n",
    "            temp = get_historical_odds(l,y)\n",
    "            to_combine.append(temp)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "hist_odds = pd.concat(to_combine)\n",
    "hist_odds = hist_odds.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "48ceeb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_a</th>\n",
       "      <th>team_b</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>winning_odds</th>\n",
       "      <th>year</th>\n",
       "      <th>league</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGD Gaming</td>\n",
       "      <td>Invictus Gaming</td>\n",
       "      <td>158</td>\n",
       "      <td>-208</td>\n",
       "      <td>158</td>\n",
       "      <td>2020</td>\n",
       "      <td>lpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Invictus Gaming</td>\n",
       "      <td>FunPlus Phoenix</td>\n",
       "      <td>-164</td>\n",
       "      <td>125</td>\n",
       "      <td>-164</td>\n",
       "      <td>2020</td>\n",
       "      <td>lpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weibo Gaming</td>\n",
       "      <td>LGD Gaming</td>\n",
       "      <td>-164</td>\n",
       "      <td>124</td>\n",
       "      <td>-164</td>\n",
       "      <td>2020</td>\n",
       "      <td>lpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Top Esports</td>\n",
       "      <td>JD Gaming</td>\n",
       "      <td>-189</td>\n",
       "      <td>142</td>\n",
       "      <td>-189</td>\n",
       "      <td>2020</td>\n",
       "      <td>lpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weibo Gaming</td>\n",
       "      <td>LGD Gaming</td>\n",
       "      <td>-114</td>\n",
       "      <td>-116</td>\n",
       "      <td>-114</td>\n",
       "      <td>2020</td>\n",
       "      <td>lpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>Hanwha Life</td>\n",
       "      <td>Gen.G</td>\n",
       "      <td>208</td>\n",
       "      <td>-270</td>\n",
       "      <td>-270</td>\n",
       "      <td>2023</td>\n",
       "      <td>lck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>Liiv SANDBOX</td>\n",
       "      <td>Brion</td>\n",
       "      <td>-147</td>\n",
       "      <td>116</td>\n",
       "      <td>-147</td>\n",
       "      <td>2023</td>\n",
       "      <td>lck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>T1</td>\n",
       "      <td>Dplus Kia</td>\n",
       "      <td>-132</td>\n",
       "      <td>104</td>\n",
       "      <td>-132</td>\n",
       "      <td>2023</td>\n",
       "      <td>lck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>KT Rolster</td>\n",
       "      <td>Hanwha Life</td>\n",
       "      <td>112</td>\n",
       "      <td>-143</td>\n",
       "      <td>112</td>\n",
       "      <td>2023</td>\n",
       "      <td>lck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>Nongshim RedForce</td>\n",
       "      <td>DRX</td>\n",
       "      <td>305</td>\n",
       "      <td>-417</td>\n",
       "      <td>305</td>\n",
       "      <td>2023</td>\n",
       "      <td>lck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2664 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 team_a           team_b  a_odds  b_odds  winning_odds  year  \\\n",
       "0            LGD Gaming  Invictus Gaming     158    -208           158  2020   \n",
       "1       Invictus Gaming  FunPlus Phoenix    -164     125          -164  2020   \n",
       "2          Weibo Gaming       LGD Gaming    -164     124          -164  2020   \n",
       "3           Top Esports        JD Gaming    -189     142          -189  2020   \n",
       "4          Weibo Gaming       LGD Gaming    -114    -116          -114  2020   \n",
       "...                 ...              ...     ...     ...           ...   ...   \n",
       "2659        Hanwha Life            Gen.G     208    -270          -270  2023   \n",
       "2660       Liiv SANDBOX            Brion    -147     116          -147  2023   \n",
       "2661                 T1        Dplus Kia    -132     104          -132  2023   \n",
       "2662         KT Rolster      Hanwha Life     112    -143           112  2023   \n",
       "2663  Nongshim RedForce              DRX     305    -417           305  2023   \n",
       "\n",
       "     league  \n",
       "0       lpl  \n",
       "1       lpl  \n",
       "2       lpl  \n",
       "3       lpl  \n",
       "4       lpl  \n",
       "...     ...  \n",
       "2659    lck  \n",
       "2660    lck  \n",
       "2661    lck  \n",
       "2662    lck  \n",
       "2663    lck  \n",
       "\n",
       "[2664 rows x 7 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "750b5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = get_historical_odds('lpl',2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7d0954e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_a</th>\n",
       "      <th>team_b</th>\n",
       "      <th>a_odds</th>\n",
       "      <th>b_odds</th>\n",
       "      <th>winning_odds</th>\n",
       "      <th>year</th>\n",
       "      <th>league</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Royal Never Give Up</td>\n",
       "      <td>LNG Esports</td>\n",
       "      <td>-164</td>\n",
       "      <td>127</td>\n",
       "      <td>-164</td>\n",
       "      <td>2022</td>\n",
       "      <td>lpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LNG Esports</td>\n",
       "      <td>Victory Five</td>\n",
       "      <td>140</td>\n",
       "      <td>-179</td>\n",
       "      <td>140</td>\n",
       "      <td>2022</td>\n",
       "      <td>lpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDward Gaming</td>\n",
       "      <td>Royal Never Give Up</td>\n",
       "      <td>-143</td>\n",
       "      <td>112</td>\n",
       "      <td>-143</td>\n",
       "      <td>2022</td>\n",
       "      <td>lpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JD Gaming</td>\n",
       "      <td>Top Esports</td>\n",
       "      <td>-115</td>\n",
       "      <td>-112</td>\n",
       "      <td>-115</td>\n",
       "      <td>2022</td>\n",
       "      <td>lpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top Esports</td>\n",
       "      <td>EDward Gaming</td>\n",
       "      <td>-120</td>\n",
       "      <td>-109</td>\n",
       "      <td>-120</td>\n",
       "      <td>2022</td>\n",
       "      <td>lpl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                team_a               team_b  a_odds  b_odds  winning_odds  \\\n",
       "0  Royal Never Give Up          LNG Esports    -164     127          -164   \n",
       "1          LNG Esports         Victory Five     140    -179           140   \n",
       "2        EDward Gaming  Royal Never Give Up    -143     112          -143   \n",
       "3            JD Gaming          Top Esports    -115    -112          -115   \n",
       "4          Top Esports        EDward Gaming    -120    -109          -120   \n",
       "\n",
       "   year league  \n",
       "0  2022    lpl  \n",
       "1  2022    lpl  \n",
       "2  2022    lpl  \n",
       "3  2022    lpl  \n",
       "4  2022    lpl  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3462fc11",
   "metadata": {},
   "source": [
    "# Sports Betting Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f01f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_differing_values(series1,series2): #Takes 2 pd Series with string values and returns values that aren't in both\n",
    "    # Find values in series1 but not in series2\n",
    "    values_in_series1 = series1[~series1.isin(series2)]\n",
    "\n",
    "    # Find values in series2 but not in series1\n",
    "    values_in_series2 = series2[~series2.isin(series1)]\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Values in series1 but not in series2:\")\n",
    "    print(values_in_series1)\n",
    "\n",
    "    print(\"Values in series2 but not in series1:\")\n",
    "    print(values_in_series2)\n",
    "\n",
    "def get_league(df, league_name): #Returns a league (\"LCS,LPL,etc.\") sorted by latest elo\n",
    "    '''\n",
    "    pass in 2 parameters:\n",
    "    df, league_name\n",
    "    '''\n",
    "    return df[df.league==league_name].sort_values('new_elo',ascending=False)\n",
    "\n",
    "def get_team(df, team,how_many):\n",
    "    '''\n",
    "    pass in 3 parameters:\n",
    "    df, teamname, how many results you want\n",
    "    '''\n",
    "    return df[df.teamname==team][['teamname','opp_name','date','result','old_elo','opp_elo','new_elo']].\\\n",
    "sort_values(by='date',ascending = False).head(how_many)\n",
    "\n",
    "def single_game_odds(df, teams, opponents, bet_odds):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with 'home' and 'away' teams with elos and implied odds.\n",
    "    \"\"\"\n",
    "    team_list = []\n",
    "    for team, opponent, odds in zip(teams, opponents, bet_odds):\n",
    "        row1 = df[df.teamname==team][['teamname', 'new_elo']]\n",
    "        row1['odds'] = odds[0]\n",
    "        row2 = df[df.teamname==opponent][['teamname', 'new_elo']]\n",
    "        row2['odds'] = odds[1]\n",
    "        row3 = pd.concat([row1, row2])\n",
    "        row3.columns = ['teamname', 'elo', 'odds']\n",
    "        row3['opponent'] = [row2.teamname.iloc[0], row1.teamname.iloc[0]]\n",
    "        row3['next_opp_elo'] = [row2.new_elo.iloc[0], row1.new_elo.iloc[0]]\n",
    "        team_list.append(row3)\n",
    "    temp = pd.concat(team_list)\n",
    "    temp = temp[['teamname', 'elo', 'opponent', 'next_opp_elo', 'odds']]\n",
    "    temp['implied_odds'] = temp.odds.apply(win_prob)\n",
    "    temp['elo_odds'] = temp.apply(lambda row: win_percent(row['elo'], row['next_opp_elo']), axis=1)\n",
    "    temp['odds_diff'] = temp.elo_odds - temp.implied_odds\n",
    "    temp.sort_values('odds_diff', ascending=False, inplace=True)\n",
    "    return temp.reset_index(drop=True)\n",
    "\n",
    "import math\n",
    "\n",
    "def series_3(probability):\n",
    "    num_wins_required = 2\n",
    "    num_games_required = (num_wins_required * 2) - 1\n",
    "\n",
    "    # Calculate the probability of winning a single game\n",
    "    p_win = probability\n",
    "\n",
    "    # Calculate the probability of losing a single game\n",
    "    p_loss = 1 - p_win\n",
    "\n",
    "    # Calculate the odds of winning a best-of-3 series\n",
    "    odds = 0\n",
    "\n",
    "    for wins in range(num_wins_required, num_games_required + 1):\n",
    "        # Calculate the number of combinations to achieve the current number of wins\n",
    "        combinations = math.comb(num_games_required, wins)\n",
    "\n",
    "        # Calculate the probability of achieving the current number of wins\n",
    "        p_current_wins = p_win ** wins * p_loss ** (num_games_required - wins)\n",
    "\n",
    "        odds += combinations * p_current_wins\n",
    "\n",
    "    return odds\n",
    "\n",
    "\n",
    "def series_5(probability):\n",
    "    num_wins_required = 3\n",
    "    num_games_required = (num_wins_required * 2) - 1\n",
    "\n",
    "    # Calculate the probability of winning a single game\n",
    "    p_win = probability\n",
    "\n",
    "    # Calculate the probability of losing a single game\n",
    "    p_loss = 1 - p_win\n",
    "\n",
    "    # Calculate the odds of winning a best-of-5 series\n",
    "    odds = 0\n",
    "\n",
    "    for wins in range(num_wins_required, num_games_required + 1):\n",
    "        # Calculate the number of combinations to achieve the current number of wins\n",
    "        combinations = math.comb(num_games_required, wins)\n",
    "\n",
    "        # Calculate the probability of achieving the current number of wins\n",
    "        p_current_wins = p_win ** wins * p_loss ** (num_games_required - wins)\n",
    "\n",
    "        odds += combinations * p_current_wins\n",
    "\n",
    "    return odds\n",
    "\n",
    "\n",
    "def best_of_3_odds(df, teams, opponents, bet_odds):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with 'home' and 'away' teams with elos and implied odds.\n",
    "    \"\"\"\n",
    "    team_list = []\n",
    "    for team, opponent, odds in zip(teams, opponents, bet_odds):\n",
    "        row1 = df[df.teamname==team][['teamname', 'new_elo']]\n",
    "        row1['odds'] = odds[0]\n",
    "        row2 = df[df.teamname==opponent][['teamname', 'new_elo']]\n",
    "        row2['odds'] = odds[1]\n",
    "        row3 = pd.concat([row1, row2])\n",
    "        row3.columns = ['teamname', 'elo', 'odds']\n",
    "        row3['opponent'] = [row2.teamname.iloc[0], row1.teamname.iloc[0]]\n",
    "        row3['next_opp_elo'] = [row2.new_elo.iloc[0], row1.new_elo.iloc[0]]\n",
    "        team_list.append(row3)\n",
    "    temp = pd.concat(team_list)\n",
    "    temp = temp[['teamname', 'elo', 'opponent', 'next_opp_elo', 'odds']]\n",
    "    temp['implied_odds'] = temp.odds.apply(win_prob)\n",
    "    temp['elo_odds'] = temp.apply(lambda row: win_percent(row['elo'], row['next_opp_elo']), axis=1)\n",
    "    temp['series_odds'] = temp.apply(lambda row: series_3(row['elo_odds']), axis=1)\n",
    "    temp['odds_diff'] = temp.series_odds - temp.implied_odds\n",
    "    temp.sort_values('odds_diff', ascending=False, inplace=True)\n",
    "    return temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2936ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_odds_diff(df):\n",
    "    df['implied_odds'] = df.odds.apply(win_prob)\n",
    "    df['elo_odds'] = df.apply(lambda row: win_percent(row['new_elo'], row['opp_elo']), axis=1)\n",
    "    df['series_odds_3'] = df.apply(lambda row: series_3(row['elo_odds']), axis=1)\n",
    "    df['series_odds_5'] = df.apply(lambda row: series_5(row['elo_odds']), axis=1)\n",
    "    df['odds_diff'] = df.elo_odds - df.implied_odds\n",
    "    df['odds_diff_3'] = df.series_odds_3 - df.implied_odds\n",
    "    df['odds_diff_5'] = df.series_odds_5 - df.implied_odds\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in df and create 'current_elo' df\n",
    "df = pd.read_csv('final.csv',index_col=0) \n",
    "raw = pd.read_csv('raw.csv',index_col=0)\n",
    "\n",
    "#'current_elo' contains every team and their latest elo\n",
    "current_elo = df[~df.teamname.duplicated(keep='last')]\\\n",
    "[['teamname','league','opp_name','old_elo','opp_elo','new_elo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d99bb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_league(current_elo,\"LFL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Input home and away teams with their odds and get back a df with the difference between betting odds and elo odds\n",
    "# home = ['Team GO','Vitality.Bee','Karmine Corp','Aegis','IZI Dream']\n",
    "# away = ['LDLC OL','BK ROG Esports','Team BDS Academy','Solary','GameWard']\n",
    "# odds = [(110,-150),(-275,200),(-188,133),(-125,-110),(150,-200)]\n",
    "# single = single_game_odds(current_elo,home,away,odds)\n",
    "# # series_odds = [(-250,175),(-163,120),(333,-500),(500,-900),(175,-250)]\n",
    "# # series = best_of_3_odds(current_elo,home,away,series_odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7519b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_team(df,'Rare Atom',4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4260f48",
   "metadata": {},
   "source": [
    "# Open html file and parse with BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5aeae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "df = pd.read_csv('final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46547b",
   "metadata": {},
   "source": [
    "CBLOL - https://www.co.bet365.com/#/AC/B151/C20889769/D48/E1510001/F10/  done\n",
    "CBLOLA - https://www.co.bet365.com/#/AC/B151/C20890093/D48/E1510001/F10/  \n",
    "LCK - https://www.co.bet365.com/#/AC/B151/C20889854/D48/E1510001/F10/  done\n",
    "LCO - https://www.co.bet365.com/#/AC/B151/C20890087/D48/E1510001/F10/  done\n",
    "LEC - https://www.co.bet365.com/#/AC/B151/C20890316/D48/E1510001/F10/  done\n",
    "LFL - https://www.co.bet365.com/#/AC/B151/C20890217/D48/E1510001/F10/  done\n",
    "LPL - https://www.co.bet365.com/#/AC/B151/C20889805/D48/E1510001/F10/  done\n",
    "SL - https://www.co.bet365.com/#/AC/B151/C20890120/D48/E1510001/F10/   done\n",
    "UL - https://www.co.bet365.com/?_h=stk6mbH5dnUh1pzKwtn2RQ%3D%3D#/AC/B151/C20889870/D48/E1510001/F10/  done\n",
    "LCS - https://www.co.bet365.com/?_h=stk6mbH5dnUh1pzKwtn2RQ%3D%3D#/AC/B151/C20889513/D48/E1510001/F10/  done\n",
    "VCS, LJL, LLA, LCO  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0891d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parses html files for each league to pull updated odds from bet365\n",
    "html_files =['lcs.html','lec.html','cblola.html','cblol.html','lck.html','lco.html','lfl.html','lpl.html','sl.html','ul.html']\n",
    "league_name = ['lcs','lec','cblola','cblol','lck','lco','lfl','lpl','sl','ul']\n",
    "\n",
    "temp = []\n",
    "for html, name in zip(html_files,league_name):\n",
    "    file_path = html  # Specify the path to the HTML file in the local directory\n",
    "\n",
    "    # Read the HTML content from the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    \n",
    "    # Get list of teams\n",
    "    team_html = soup.select('div.ses-ParticipantFixtureDetailsHigherEsports_Team')\n",
    "    team_list = [i.text for i in team_html]\n",
    "\n",
    "    # Get list of odds for each team\n",
    "    span_element = soup.find_all('span', class_='src-ParticipantOddsOnly50_Odds')\n",
    "    odds_list = [int(i.text) for i in span_element]\n",
    "    \n",
    "    df_temp = pd.DataFrame({'teamname':team_list,'odds':odds_list})\n",
    "    df_temp = add_opp_name(df_temp)\n",
    "    df_temp['league'] = name\n",
    "    temp.append(df_temp)\n",
    "    \n",
    "bet = pd.concat(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_elo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bccb9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df with implied odds, elo odds, and the difference for all upcoming games\n",
    "temp = pd.merge(bet,current_elo[['teamname','new_elo']],on='teamname')\n",
    "monies = pd.merge(temp,current_elo[['teamname','new_elo']],left_on='opp_name',right_on='teamname')\n",
    "del monies['teamname_y']\n",
    "monies.columns = ['teamname','odds','opp_name','league','new_elo','opp_elo']\n",
    "monies = calc_odds_diff(monies)\n",
    "monies1 =monies[['teamname','league','odds','opp_name','new_elo','opp_elo','odds_diff']].sort_values(['league','odds_diff'],ascending=False)\n",
    "monies1 = monies1[monies1.odds_diff>.08]\n",
    "monies3 =monies[['teamname','league','odds','opp_name','new_elo','opp_elo','odds_diff_3']].sort_values(['league','odds_diff_3'],ascending=False)\n",
    "monies3 = monies3[monies3.odds_diff_3>.08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc7a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_team(df,\"Ground Zero Gaming\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "monies1[~(monies1.league=='lck')&~(monies1.league=='lpl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "monies3[(monies3.league=='lck')|(monies3.league=='lpl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "monies[monies.league=='lpl'].sort_values(['league','odds_diff_3'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aac6cb",
   "metadata": {},
   "source": [
    "# Don't go past here yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78849392",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = train.select_dtypes(['int','float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(groupby):\n",
    "    groupby['target']=groupby['result'].shift(-1)\n",
    "    return groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(df):\n",
    "    df = df.groupby('teamname').apply(create_target)\n",
    "    df.loc[pd.isnull(df.target),'target'] =2\n",
    "    df.target = df.target.astype(int,errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b88c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_target(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #scale all numerical columns\n",
    "\n",
    "removed_columns = ['teamname','league','date','target','opp_name']\n",
    "selected_columns = df.columns[~df.columns.isin(removed_columns)]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[selected_columns] = scaler.fit_transform(df[selected_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling averages for columns, concat as new columns to df\n",
    "\n",
    "\n",
    "def rolling(team):\n",
    "    rolling = team.rolling(10).mean()\n",
    "    return rolling\n",
    "\n",
    "def add_rolling(df):\n",
    "    cols = ['gamelength','teamkills','teamdeaths','firstblood','dragons','barons','opp_barons','towers','opp_towers',\\\n",
    "       'inhibitors','opp_inhibitors','damagetochampions','damagetakenperminute','wardsplaced','wardskilled',\\\n",
    "       'controlwardsbought','totalgold','gspd']\n",
    "\n",
    "    df_rolling=df[list(cols)+['teamname']]\n",
    "    \n",
    "    \n",
    "    df_rolling = df_rolling.groupby('teamname',group_keys=False)[cols].apply(rolling)\n",
    "\n",
    "    rolling_cols = [f'{col}_rolling' for col in df_rolling.columns]\n",
    "    df_rolling.columns = rolling_cols\n",
    "    df = pd.concat([df,df_rolling],axis=1)\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_opp(team):\n",
    "    team['next_opp'] = team['opp_name'].shift(-1)\n",
    "    return team\n",
    "def add_opp(df):\n",
    "    df = df.groupby('teamname').apply(next_opp)\n",
    "    df.loc[df.next_opp.isnull(),'next_opp'] = 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_opp(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_side(team):\n",
    "    team['next_blue'] = team['blue_side'].shift(-1)\n",
    "    return team\n",
    "\n",
    "def add_next_side(df):\n",
    "    df = df.groupby('teamname').apply(next_side)\n",
    "    df.loc[df.next_blue.isnull(),'next_blue']=2\n",
    "    df.next_blue = df.next_blue.astype(int,errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_date(team):\n",
    "    team['next_date'] = team['date'].shift(-1)\n",
    "    return team\n",
    "\n",
    "def add_next_date(df):\n",
    "    df = df.groupby('teamname').apply(next_date)\n",
    "    df.loc[df.next_date.isnull(),'next_date']=2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee28602",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = df.merge(df[rolling_cols + [\"next_opp\", \"next_date\", \"teamname\"]], left_on=[\"teamname\", \"next_date\"], \\\n",
    "                right_on=[\"next_opp\", \"next_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3849bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "def create_objects():\n",
    "    rr = RidgeClassifier(solver ='sag',normalize=False,)\n",
    "    split = TimeSeriesSplit(n_splits=3)\n",
    "    sfs = SequentialFeatureSelector(rr, n_features_to_select=14,direction='backward',cv=split,n_jobs=-1)\n",
    "\n",
    "create_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = list(full.columns[full.dtypes=='object']) + removed_columns\n",
    "selected_columns = full.columns[~full.columns.isin(removed_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98214a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.fit(full[selected_columns],full['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5df7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = selected_columns[sfs.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628bef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = backtest(full,rr,selectors,'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf2301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictions.actual,predictions.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f054f6a",
   "metadata": {},
   "source": [
    ".5665 'forward', rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c0ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_split(x, num_bins): #Split my df into equal splits to perform backtesting\n",
    "    quotient, remainder = divmod(x, num_bins)\n",
    "    bins = [quotient + 1] * remainder + [quotient] * (num_bins - remainder)\n",
    "    count = 0\n",
    "    new_list = []\n",
    "    for b in bins:\n",
    "        count += b\n",
    "        new_list.append(count)\n",
    "    return new_list\n",
    "\n",
    "splits = near_split(df.shape[0],5)\n",
    "last_split = splits[4]-splits[3] #Difference between last two values for final 'test' set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data,model,predictors,target):\n",
    "    all_predictions= []\n",
    "    \n",
    "    for i in range(0,len(splits)-1):\n",
    "        train = data.loc[:splits[i]]\n",
    "        test = data.loc[splits[i]:splits[i]+last_split]\n",
    "        \n",
    "        model.fit(train[predictors],train[target])\n",
    "        preds = model.predict(test[predictors])\n",
    "        preds = pd.Series(preds,index=test.index)\n",
    "        combined = pd.concat([test[target],preds],axis=1)\n",
    "        combined.columns = ['actual','prediction']\n",
    "        \n",
    "        all_predictions.append(combined)\n",
    "        \n",
    "    return pd.concat(all_predictions)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = backtest(full,rr,selectors,'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9140cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictions.actual,predictions.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d52e2b",
   "metadata": {},
   "source": [
    "### optimize ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full[selectors]\n",
    "y = full['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "ridge = linear_model.Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02daa069",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(\"pca\", pca),\n",
    "                        (\"ridge\", ridge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "normalize = [True, False]\n",
    "solver = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                      ridge__normalize=normalize,\n",
    "                      ridge__solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88430bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS = GridSearchCV(pipe, parameters)\n",
    "clf_GS.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Number Of Components:\", clf_GS.best_estimator_.get_params()[\"pca__n_components\"])\n",
    "print(); print(clf_GS.best_estimator_.get_params()[\"ridge\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51ff65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
