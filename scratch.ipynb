{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4becc1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5971b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads the updated csv for the 2023 season\n",
    "import gdown\n",
    "\n",
    "def update_df():\n",
    "    '''\n",
    "    Download most recent csv file, concat with rest of data, return the full df\n",
    "    '''\n",
    "    output = \"lol_2023.csv\" #What to save the downloaded file as\n",
    "    id = \"1XXk2LO0CsNADBB1LRGOV5rUpyZdEZ8s2\" #The id from the google drive file\n",
    "    gdown.download(id=id, output=output, quiet=False)\n",
    "    \n",
    "    df_2021 = pd.read_csv('lol_2021.csv')\n",
    "    df_2022 = pd.read_csv('lol_2022.csv')\n",
    "    df_2023 = pd.read_csv('lol_2023.csv')\n",
    "    df = pd.concat([df_2021,df_2022,df_2023])\n",
    "    return df\n",
    "\n",
    "def get_wiki():\n",
    "    '''\n",
    "    Returns chart from wikipedia containing info for Tier 1 and Tier 2 leagues\n",
    "    Returns tier1, tier2\n",
    "    '''\n",
    "    wiki = pd.read_html('https://en.wikipedia.org/wiki/List_of_League_of_Legends_leagues_and_tournaments')\n",
    "    return wiki[1], wiki[3]\n",
    "\n",
    "def add_opp_name(df): #tup = list of tuples\n",
    "    # Create an 'opp_name' column for each row\n",
    "    evens = range(0,df.shape[0],2)\n",
    "    odds = range(1,df.shape[0],2)\n",
    "    tup = [(a,b) for a,b in zip(evens,odds)] # list of tuples\n",
    "    \n",
    "    for t in tup: #iterate through list of tuples\n",
    "        a,b= t #unpack each tuple into two values\n",
    "        df.loc[a,'opp_name']=df.teamname.loc[b] #create new column w/opp_name\n",
    "        df.loc[b,'opp_name']=df.teamname.loc[a]\n",
    "    return df\n",
    "\n",
    "def win_percent(elo_a,elo_b): #Calculate odds to win based off of elo rankings\n",
    "    return 1/(1+10**((elo_b-elo_a)/400)) #elo_a is who you're calculating for, elo_b is opponent\n",
    "\n",
    "def win_prob(x): # x is the American odds (-110,110,etc.) Calculates probably of winning\n",
    "    if x < 0 :\n",
    "        x = x*-1\n",
    "        return x / (x + 100)\n",
    "    else: \n",
    "        return 100 / (x + 100)\n",
    "\n",
    "def gain_elo(elo,opp_elo,k=32): #Gain elo after a win, k=24, expected = 1\n",
    "    return int(elo+k*(1-win_percent(elo,opp_elo)))\n",
    "\n",
    "def lose_elo(elo,opp_elo,k=32): #Lose elo after a loss, k=24, expected = 0\n",
    "    return int(elo+k*(0-win_percent(elo,opp_elo)))\n",
    "\n",
    "def tie_elo(elo,opp_elo,k=32): #Lose elo after a loss, k=24, expected = .5\n",
    "    return int(elo+k*(.5-win_percent(elo,opp_elo)))\n",
    "\n",
    "\n",
    "def wrangle_df(df):\n",
    "    leagues = ['LCK','LPL','LEC','LCS','PCS','VCS','CBLOL','LJL','LLA'] # These are my 9 tier 1 leagues that I'll keep\n",
    "    \n",
    "    df = df[df.league.isin(leagues)] #Filter out non Tier-1 leagues\n",
    "    df = df[df.position=='team'] #Remove individual player stats\n",
    "    \n",
    "    df.split = df.split.str.replace('Split 1','Spring').str.replace('Split 2','Summer') #Rename 'split' names\n",
    "    df.split = df.split.str.replace('Opening','Spring').str.replace('Closing','Summer')\n",
    "\n",
    "    cols = ['teamname','league','split','date', 'side', 'gamelength','game', 'result', 'teamkills', \n",
    "            'teamdeaths', 'firstblood', 'position', 'dragons', 'barons', 'opp_barons','towers', 'opp_towers', \n",
    "            'inhibitors', 'opp_inhibitors', 'damagetochampions', 'damagetakenperminute', 'wardsplaced', 'wardskilled', \n",
    "            'controlwardsbought', 'totalgold', 'gspd'] #Columns to keep\n",
    "\n",
    "    df = df[cols] #Remove unwanted columns\n",
    "    df = df.dropna() #Drop nan values\n",
    "    \n",
    "    df.date = pd.to_datetime(df.date,infer_datetime_format=True) #Change to datetime object\n",
    "    del df['position'] # Delete 'position' column\n",
    "    df = df.sort_values('date') #Sort by date\n",
    "    df = df.reset_index(drop=True) #Reset index\n",
    "    df.side = np.where(df.side=='Blue',1,0) #Add 'side' column for 'blue' or 'red'\n",
    "    df.rename(columns={'side':'blue_side'},inplace = True) #Change 'side' to 'blue_side'\n",
    "    \n",
    "    df['old_elo']=np.NaN #create new elo column\n",
    "    df['new_elo']=np.NaN\n",
    "    df['opp_elo']=np.NaN\n",
    "    df.loc[df[~df.teamname.duplicated()].index,'old_elo']=1200 #set elo for first game to 1200 for each team\n",
    "\n",
    "    df = add_opp_name(df) #adds opponents' name\n",
    "    \n",
    "    for i in range(0,df.shape[0]):\n",
    "        opp_name = df.loc[i,'opp_name']\n",
    "        df.loc[i,'opp_elo'] = df[(df.teamname==opp_name)&(~df.old_elo.isna())]['old_elo'].iloc[-1]\n",
    "        if df.loc[i,'result'] == 1:\n",
    "            df.loc[i,'new_elo'] = gain_elo(df.loc[i,'old_elo'],df.loc[i,'opp_elo'])\n",
    "        else:\n",
    "            df.loc[i,'new_elo'] = lose_elo(df.loc[i,'old_elo'],df.loc[i,'opp_elo'])\n",
    "\n",
    "        team_name = df.loc[i,'teamname']\n",
    "        try:\n",
    "            next_game_index = df[(df.teamname==team_name)&df.old_elo.isna()]['old_elo'].index[0]\n",
    "            df.loc[next_game_index,'old_elo'] = df[(df.teamname==team_name)&(~df.new_elo.isna())]['new_elo'].iloc[-1]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    df.to_csv('final.csv') #Save to csv file\n",
    "    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad161c1e",
   "metadata": {},
   "source": [
    "# Update and wrangle professional games for Spring and Summer splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df981050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1XXk2LO0CsNADBB1LRGOV5rUpyZdEZ8s2\n",
      "To: /Users/thegootch/codeup-data-science/league/lol_2023.csv\n",
      "100%|███████████████████████████████████████| 32.0M/32.0M [00:34<00:00, 930kB/s]\n",
      "/var/folders/fz/0282wvb93rn0lm_p0nscw1sm0000gn/T/ipykernel_11021/3407151170.py:1: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  df = update_df()\n"
     ]
    }
   ],
   "source": [
    "df = update_df()\n",
    "df.to_csv('raw.csv')\n",
    "df = wrangle_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed48bc68",
   "metadata": {},
   "source": [
    "# Sports Betting Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01218132",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final.csv',index_col=0)\n",
    "raw = pd.read_csv('raw.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7f9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa0df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['old_elo']=np.NaN #create new elo column\n",
    "df['new_elo']=np.NaN\n",
    "df['opp_elo']=np.NaN\n",
    "df.loc[df[~df.teamname.duplicated()].index,'old_elo']=1200 #set elo for first game to 1200 for each team\n",
    "\n",
    "df = add_opp_name(df) #adds opponents' name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61adbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,df.shape[0]):\n",
    "    opp_name = df.loc[i,'opp_name']\n",
    "    df.loc[i,'opp_elo'] = df[(df.teamname==opp_name)&(~df.old_elo.isna())]['old_elo'].iloc[-1]\n",
    "    if df.loc[i,'result'] == 1:\n",
    "        df.loc[i,'new_elo'] = gain_elo(df.loc[i,'old_elo'],df.loc[i,'opp_elo'])\n",
    "    else:\n",
    "        df.loc[i,'new_elo'] = lose_elo(df.loc[i,'old_elo'],df.loc[i,'opp_elo'])\n",
    "        \n",
    "    team_name = df.loc[i,'teamname']\n",
    "    try:\n",
    "        next_game_index = df[(df.teamname==team_name)&df.old_elo.isna()]['old_elo'].index[0]\n",
    "        df.loc[next_game_index,'old_elo'] = df[(df.teamname==team_name)&(~df.new_elo.isna())]['new_elo'].iloc[-1]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df.to_csv('final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30564e88",
   "metadata": {},
   "source": [
    "# Start here unless you want to update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a1d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc760423",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_elo = df[~df.teamname.duplicated(keep='last')][['teamname','league','opp_name','old_elo','opp_elo','new_elo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_league(team):\n",
    "    return current_elo[current_elo.league==team].sort_values('new_elo',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f6b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_league(\"LCS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ef68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teams(df,teams,opponents,bet_odds): #returns df with 'home' and 'away' teams with elos and implied odds\n",
    "    team_list = []\n",
    "    for team, opponent,odds in zip(teams,opponents,bet_odds):\n",
    "        row1 = df[df.teamname==team][['teamname','new_elo']]\n",
    "        row1['odds'] = odds[0]\n",
    "        row2 = df[df.teamname==opponent][['teamname','new_elo']]\n",
    "        row2['odds'] = odds[1]\n",
    "        row3 = pd.concat([row1,row2])\n",
    "        row3.columns = ['teamname','elo','odds']\n",
    "        row3['opponent'] = [row2.teamname.iloc[0],row1.teamname.iloc[0]]\n",
    "        row3['next_opp_elo'] = [row2.new_elo.iloc[0],row1.new_elo.iloc[0]]\n",
    "        team_list.append(row3)\n",
    "    temp = pd.concat(team_list)\n",
    "    temp = temp[['teamname','elo','opponent','next_opp_elo','odds']]\n",
    "    temp['implied_odds'] = temp.odds.apply(win_prob)\n",
    "    return temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e71ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input home and away teams with their odds and get back a df with the difference between betting odds and elo odds\n",
    "home = ['Cloud9','eStar']\n",
    "away = ['Bilibili Gaming','Rogue Warriors']\n",
    "odds = [(-230,280),(160,-110)]\n",
    "monies = get_teams(current_elo,home,away,odds)\n",
    "monies['elo_odds'] = 0\n",
    "\n",
    "for i in range(0,monies.shape[0]):\n",
    "    monies.loc[i,'elo_odds'] = win_percent(monies.loc[i,'elo'],monies.loc[i,'next_opp_elo'])\n",
    "monies['odds_diff'] = monies.elo_odds-monies.implied_odds\n",
    "monies.sort_values('odds_diff',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b5bf54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "monies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a385f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_prob(180) #based on betting odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_percent(1389,1262) #based on elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2050a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_elo[(current_elo.teamname == 'Bilibili Gaming')|(current_elo.teamname == 'Movistar R7')].sort_values('new_elo',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e007c",
   "metadata": {},
   "source": [
    "# Don't go past here yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78849392",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = train.select_dtypes(['int','float']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44910fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df.result,df.teamkills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0caea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['result'].sort_values() #Worth exploring gspd, barons, dragons, damagetochampions, firstblood, wardskilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cols(df):\n",
    "    columns = ['blue_side', 'firstblood' ,'gspd', 'barons', 'dragons', 'damagetochampions','wardsplaced', 'wardskilled']\n",
    "\n",
    "    plt.figure(figsize = (10,20))\n",
    "    count = 1\n",
    "    for col in columns:\n",
    "        plt.subplot(4,2,count)\n",
    "        plt.title(col)\n",
    "        sns.barplot(data=df,x='result',y=col)\n",
    "        count+=1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cols(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d14cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['blue_side', 'firstblood' ,'gspd', 'barons', 'dragons', 'damagetochampions','wardsplaced', 'wardskilled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4754fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tstat(train):  \n",
    "    ind=0\n",
    "    temp_list = []\n",
    "    for col in columns:\n",
    "        t,p= ttest_ind(train[col],train.result, equal_var=False)\n",
    "        temp = pd.DataFrame({'column':col,'t_stat':t,'p_value':p},index=[ind])\n",
    "        ind+=1\n",
    "        temp_list.append(temp)\n",
    "    tstat = pd.concat(temp_list)\n",
    "    tstat.p_value = tstat.p_value.round(decimals=2)\n",
    "    return tstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b1e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstat = get_tstat(train)\n",
    "tstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62500c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t,p= ttest_ind(train.blue_side,train.result, equal_var=False)\n",
    "print(f'T-Statistic:{round(t,2)}  P-Value:{round(p,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(groupby):\n",
    "    groupby['target']=groupby['result'].shift(-1)\n",
    "    return groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(df):\n",
    "    df = df.groupby('teamname').apply(create_target)\n",
    "    df.loc[pd.isnull(df.target),'target'] =2\n",
    "    df.target = df.target.astype(int,errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b88c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_target(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969dda7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c9198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24692980",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler #scale all numerical columns\n",
    "\n",
    "removed_columns = ['teamname','league','date','target','opp_name']\n",
    "selected_columns = df.columns[~df.columns.isin(removed_columns)]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[selected_columns] = scaler.fit_transform(df[selected_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb7f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling averages for columns, concat as new columns to df\n",
    "\n",
    "\n",
    "def rolling(team):\n",
    "    rolling = team.rolling(10).mean()\n",
    "    return rolling\n",
    "\n",
    "def add_rolling(df):\n",
    "    cols = ['gamelength','teamkills','teamdeaths','firstblood','dragons','barons','opp_barons','towers','opp_towers',\\\n",
    "       'inhibitors','opp_inhibitors','damagetochampions','damagetakenperminute','wardsplaced','wardskilled',\\\n",
    "       'controlwardsbought','totalgold','gspd']\n",
    "\n",
    "    df_rolling=df[list(cols)+['teamname']]\n",
    "    \n",
    "    \n",
    "    df_rolling = df_rolling.groupby('teamname',group_keys=False)[cols].apply(rolling)\n",
    "\n",
    "    rolling_cols = [f'{col}_rolling' for col in df_rolling.columns]\n",
    "    df_rolling.columns = rolling_cols\n",
    "    df = pd.concat([df,df_rolling],axis=1)\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed2fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_opp(team):\n",
    "    team['next_opp'] = team['opp_name'].shift(-1)\n",
    "    return team\n",
    "def add_opp(df):\n",
    "    df = df.groupby('teamname').apply(next_opp)\n",
    "    df.loc[df.next_opp.isnull(),'next_opp'] = 2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_opp(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a391d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_side(team):\n",
    "    team['next_blue'] = team['blue_side'].shift(-1)\n",
    "    return team\n",
    "\n",
    "def add_next_side(df):\n",
    "    df = df.groupby('teamname').apply(next_side)\n",
    "    df.loc[df.next_blue.isnull(),'next_blue']=2\n",
    "    df.next_blue = df.next_blue.astype(int,errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_date(team):\n",
    "    team['next_date'] = team['date'].shift(-1)\n",
    "    return team\n",
    "\n",
    "def add_next_date(df):\n",
    "    df = df.groupby('teamname').apply(next_date)\n",
    "    df.loc[df.next_date.isnull(),'next_date']=2\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.next_blue==2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee28602",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = df.merge(df[rolling_cols + [\"next_opp\", \"next_date\", \"teamname\"]], left_on=[\"teamname\", \"next_date\"], \\\n",
    "                right_on=[\"next_opp\", \"next_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e68a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.next_blue.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = full, x='result',y='blue_side')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[(df.blue_side==1) & (df.result == 1)])/(df.shape[0]/2) #Establishes a baseline - blue team wins 52% of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3849bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "def create_objects():\n",
    "    rr = RidgeClassifier(solver ='sag',normalize=False,)\n",
    "    split = TimeSeriesSplit(n_splits=3)\n",
    "    sfs = SequentialFeatureSelector(rr, n_features_to_select=14,direction='backward',cv=split,n_jobs=-1)\n",
    "\n",
    "create_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = list(full.columns[full.dtypes=='object']) + removed_columns\n",
    "selected_columns = full.columns[~full.columns.isin(removed_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98214a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.fit(full[selected_columns],full['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5df7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = selected_columns[sfs.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628bef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = backtest(full,rr,selectors,'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf2301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictions.actual,predictions.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f054f6a",
   "metadata": {},
   "source": [
    ".5665 'forward', rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c0ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_split(x, num_bins): #Split my df into equal splits to perform backtesting\n",
    "    quotient, remainder = divmod(x, num_bins)\n",
    "    bins = [quotient + 1] * remainder + [quotient] * (num_bins - remainder)\n",
    "    count = 0\n",
    "    new_list = []\n",
    "    for b in bins:\n",
    "        count += b\n",
    "        new_list.append(count)\n",
    "    return new_list\n",
    "\n",
    "splits = near_split(df.shape[0],5)\n",
    "last_split = splits[4]-splits[3] #Difference between last two values for final 'test' set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a511bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data,model,predictors,target):\n",
    "    all_predictions= []\n",
    "    \n",
    "    for i in range(0,len(splits)-1):\n",
    "        train = data.loc[:splits[i]]\n",
    "        test = data.loc[splits[i]:splits[i]+last_split]\n",
    "        \n",
    "        model.fit(train[predictors],train[target])\n",
    "        preds = model.predict(test[predictors])\n",
    "        preds = pd.Series(preds,index=test.index)\n",
    "        combined = pd.concat([test[target],preds],axis=1)\n",
    "        combined.columns = ['actual','prediction']\n",
    "        \n",
    "        all_predictions.append(combined)\n",
    "        \n",
    "    return pd.concat(all_predictions)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b24cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = backtest(full,rr,selectors,'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9140cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictions.actual,predictions.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d52e2b",
   "metadata": {},
   "source": [
    "### optimize ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full[selectors]\n",
    "y = full['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b5047",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "ridge = linear_model.Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02daa069",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(\"pca\", pca),\n",
    "                        (\"ridge\", ridge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = list(range(1,X.shape[1]+1,1))\n",
    "normalize = [True, False]\n",
    "solver = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]\n",
    "parameters = dict(pca__n_components=n_components,\n",
    "                      ridge__normalize=normalize,\n",
    "                      ridge__solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88430bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS = GridSearchCV(pipe, parameters)\n",
    "clf_GS.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Number Of Components:\", clf_GS.best_estimator_.get_params()[\"pca__n_components\"])\n",
    "print(); print(clf_GS.best_estimator_.get_params()[\"ridge\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea60810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51ff65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
